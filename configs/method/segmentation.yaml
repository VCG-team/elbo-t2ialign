# segmentation process settings (segmentation.py)
use_img2text: True
special_token: "''"
# see ./configs/io/io.yaml for details
# by io.yaml default, use_cls_prediction is False
# for open vocabulary segmentation, we need to use predicted classes to construct dataset
use_cls_predict: True
delay_collection: False # whether to delay the collection of attention maps
collect_timesteps: [1, 25, 50, 75, 100, 125, 150] # timesteps to collect attention maps, only valid when delay_collection is True
collect_with_original_eps: True # whether to collect attention maps with original eps, only valid when delay_collection is True
self_att_times: 1 # times to multiply self_att
self_att_aug_times: 1 # times to multiply self_att_aug

# ptp attention settings (ptp_utils.py)
# diffusion models use unet/dit with cross/self attentions to predict noise
# as image pass unet/dit block, image and attention resolution change accordingly
# only part of attn layers have strong semantic information(https://arxiv.org/abs/2309.04109)
# so we can choose some layers to achieve better performance
cross_gaussian_var: 1.2 # variance of gaussian distribution for cross attention
self_weight: [1, 0, 0, 0, 0, 0, 1] # weight of self attention for each resolution
merge_type: "latent" # merge 'latent' or 'attention' of target and source image
target_factor: 0.5 # ratio of target merged into source, result = source + target_factor * (source - target)

# dds loss settings (dds_utils.py)
optimize_timesteps: [1, 25, 50, 75, 100, 125, 150]
loss_type: "dds" # loss function, "dds" or "sds" or "none"
loss_factor: 2000.0 # coefficient of loss
enable_mask: False # whether enable mask for loss calculation
lr: 1.0e-1 # learning rate
guidance_scale: null # null or float, if null, use the default value of pipeline
alpha_exp: 0.0
sigma_exp: 0.0
