# segmentation process settings (segmentation.py)
use_blip: True
# see ./configs/io/io.yaml for details
# by io.yaml default, use_cls_prediction is False
# for open vocabulary segmentation, we need to use predicted classes to construct dataset
use_cls_predict: True
delay_collection: False # whether to delay the collection of attention maps
collect_timesteps: [1, 25, 50, 75, 100, 125, 150] # timesteps to collect attention maps, only valid when delay_collection is True
collect_with_original_eps: True # whether to collect attention maps with original eps, only valid when delay_collection is True
self_att_times: 1 # times to multiply self_att
self_att_aug_times: 1 # times to multiply self_att_aug

# ptp attention settings (ptp_utils.py)
# diffusion models usually use symmetric unet with cross/self attentions to predict noise
# as image pass down->mid->up unet block, image and attention resolution change accordingly
# only part of attn layers have strong semantic information(https://arxiv.org/abs/2309.04109)
# so we can choose some layers to achieve better performance
target_factor: 0.5 # ratio of target latent merged into source latent, x = source + target_factor * (source - target)
# this equation must be satisfied: len(cross_weight) = len(self_weight) = len(pipe.unet.config.down_block_types) * 2 - 1
cross_weight: [1, 1, 10, 15, 10, 1, 1] # weight of cross att for each resolution
self_weight: [1, 0, 0, 0, 0, 0, 1] # weight of self attention for each resolution

# dds loss settings (dds_utils.py)
optimize_timesteps: [1, 25, 50, 75, 100, 125, 150]
loss_type: "dds" # loss function, "dds" or "sds" or "none"
loss_factor: 2000.0 # coefficient of loss
lr: 1.0e-1 # learning rate
guidance_scale: null # null or float, if null, use the default value of pipeline
alpha_exp: 0.0
sigma_exp: 0.0
