# segmentation process settings (run_segmentation.py)
elbo_text:
  type: "prompt" # "prompt" or "file"
  prompt: "a photo of {source_cls}"
source_text:
  type: "prompt" # "prompt" or "file"
  prompt: "a photo of {classes}"
# timesteps to get elbo prediction, refer to Diffusion Classifier(ICCV 2023)
# format: [start, end(exclude), step] or ["random", start, end(include), num]
elbo_timesteps:
  - [1, 999, 50]
# timesteps to collect attention maps, default to align with ddim inversion default step
# format: [start, end(exclude), step] or ["random", start, end(include), num]
collect_timesteps:
  - [20, 201, 20]
# path to elbo_min_max.json file.
# if not None, use elbo_min_max.json to normalize cross attention
# if None, recompute elbo or omit elbo depending on segmentation method
elbo_path: ""
elbo_strength: 3.0 # strength of using elbo to normalize cross attention, equals to 1/gamma in the paper
fix_temperature: False # whether to fix temperature of normalizing cross attention
guidance_scale: null # null or float, if null, use the default value of pipeline
save_img: False # whether to save optimized images(decoded z_target)
save_cross_att: False # whether to save cross attention maps
save_elbo: False # whether to save relative elbo

# attention control settings (attention_control.py)
# diffusion models use unet/dit with cross/self attentions to predict noise
# as image pass unet/dit block, image and attention resolution change accordingly
# only part of attn layers have strong semantic information(https://arxiv.org/abs/2309.04109)
# so we can choose some layers to achieve better performance
cross_gaussian_var: 0 # variance of gaussian distribution for cross attention
cross_weight: [1, 1, 10, 15, 10, 1, 1] # enabled when cross_gaussian_var == 0, weight of cross attention for each resolution
self_weight: # weight of self attention for each resolution
  - [1, 0, 0, 0, 0, 0, 1]
  - [0, 0, 0, 0, 0, 0, 1]
