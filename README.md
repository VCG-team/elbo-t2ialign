# DDSSEG

## Setup

### Python Environment

A suitable [conda](https://conda.io/) environment named `ddsseg` can be created and setup with:

```bash
conda env create -f environment.yaml
conda activate ddsseg
# download spacy model for part-of-speech tags
python -m spacy download en_core_web_sm
```

### Data Preparation

1. We mainly used [mmsegmentation](https://github.com/open-mmlab/mmsegmentation) to prepare the data. Specifically, we followed this [guideline](https://github.com/open-mmlab/mmsegmentation/blob/main/docs/en/user_guides/2_dataset_prepare.md) to prepare PASCAL VOC (including VOCaug), PASCAL Context and COCO Stuff 164k datasets.

2. After preparing these datasets, please link them to the project folder. The overall file structure is as follows:
    ```
    ddsseg
    ├── configs
    ├── data
    ├── utils
    ├── README.md
    ├── ...
    ├── VOCdevkit
    │   ├── VOC2012
    │   │   ├── JPEGImages
    │   │   ├── SegmentationClassAug
    │   │   ├── ImageSets
    │   │   │   ├── Segmentation
    │   ├── VOC2010
    │   │   ├── JPEGImages
    │   │   ├── SegmentationClassContext
    │   │   ├── ImageSets
    │   │   │   ├── SegmentationContext
    │   │   │   │   ├── train.txt
    │   │   │   │   ├── val.txt
    │   ├── VOCaug
    │   │   ├── dataset
    ├── coco_stuff164k
    │   ├── images
    │   │   ├── train2017
    │   │   ├── val2017
    │   ├── annotations
    │   │   ├── train2017
    │   │   ├── val2017
    ```

3. Finally, download [SBD dataset](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6126343&casa_token=cOQGLW2KWqUAAAAA:Z-QHpQPf8Pnb07A75yBm2muYjqJwYUYPFbwwxMFHRcjRX0zl45kEGNqyTEPH7irB2QbabZbn&tag=1) annotations via this [link](https://www.dropbox.com/s/oeu149j8qtbs1x0/SegmentationClassAug.zip?dl=0). After downloading, replace `./VOCdevkit/VOC2012/SegmentationClassAug` with the downloaded folder. This step makes sure the evaluation is consistent with [MCTFormer](https://github.com/xulianuwa/MCTformer).

> Note:
> 1. `./data/voc/cls_labels.npy` is copied from [MCTFormer](https://github.com/xulianuwa/MCTformer).
> 2. `./data/context/cls_labels.npy` and `./data/coco/cls_labels.npy` are generated by unreleased script(have been carefully checked).
> 3. `**/cls_labels.npy` have the same format(have been carefully checked).
> 4. `./data/*/val_id.txt` all keep the same with validation set of original datasets(have been carefully checked).
> 5. if you have trouble downloading VOCaug dataset, please refer to [this PR](https://github.com/open-mmlab/mmsegmentation/pull/3654) to mmsegmentation.
> 6. the SBD dataset download link is from [MCTFormer](https://github.com/xulianuwa/MCTformer) README.

## Usage

Reproducing the results will need about 10G GPU memory. We are still working on reducing the memory cost for reproductions.

You can change configuration file in `config` folder to test different settings. Welcome to open an issue if you have any questions. 

### Reproduce PASCAL VOC Results

```bash
# 1. classification
python classification.py --dataset-cfg ./configs/dataset/voc.yaml
# 2. segmentation
python segmentation.py --dataset-cfg ./configs/dataset/voc.yaml
# 3. evaluation
python evaluation.py --dataset-cfg ./configs/dataset/voc.yaml
```

After running the above script, results will be saved at `./output/voc`. You can change the output folder by modifying `./configs/io/io.yaml`.

### Reproduce PASCAL Context Results

```bash
# 1. classification
python classification.py --dataset-cfg ./configs/dataset/context.yaml
# 2. segmentation
python segmentation.py --dataset-cfg ./configs/dataset/context.yaml
# 3. evaluation
python evaluation.py --dataset-cfg ./configs/dataset/context.yaml
```

After running the above script, results will be saved at `./output/context`. You can change the output folder by modifying `./configs/io/io.yaml`.

### Reproduce COCO Results

```bash
# 1. classification
python classification.py --dataset-cfg ./configs/dataset/coco.yaml
# 2. segmentation
python segmentation.py --dataset-cfg ./configs/dataset/coco.yaml
# 3. evaluation
python evaluation.py --dataset-cfg ./configs/dataset/coco.yaml
```

After running the above script, results will be saved at `./output/coco`. You can change the output folder by modifying `./configs/io/io.yaml`.

## Credits

We appreciate all open source projects that we use in this project:

- [mmsegmentation](https://github.com/open-mmlab/mmsegmentation), [diffusers](https://github.com/huggingface/diffusers), [transformers](https://github.com/huggingface/transformers)
- [MCTFormer](https://github.com/xulianuwa/MCTformer), [prompt-to-prompt](https://github.com/google/prompt-to-prompt), [clip-es](https://github.com/linyq2117/CLIP-ES)
- ...

## Citation
```bibtex

```
